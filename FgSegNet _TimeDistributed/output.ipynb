{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on Mon Sep 29 22:22:22 2017\n",
    "\n",
    "@author: longang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_ipython().magic(u'load_ext autoreload')\n",
    "get_ipython().magic(u'autoreload 2')\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os, sys\n",
    "\n",
    "# set current working directory\n",
    "cur_dir = os.getcwd()\n",
    "os.chdir(cur_dir)\n",
    "sys.path.append(cur_dir)\n",
    "\n",
    "# =============================================================================\n",
    "#  For reprodocable results\n",
    "# =============================================================================\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1234)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "import keras, glob\n",
    "from keras.preprocessing import image as kImage\n",
    "from skimage.transform import pyramid_gaussian\n",
    "from sklearn.utils import compute_class_weight\n",
    "from FgSegNet_M_S_module import FgSegNet_M_S_module\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "# alert the user\n",
    "if keras.__version__!= '2.0.6' or tf.__version__!='1.1.0' or sys.version_info[0]<3:\n",
    "    print('We implemented using [keras v2.0.6, tensorflow-gpu v1.1.0, python v3.6.3], other versions than these may cause errors somehow!\\n')\n",
    "\n",
    "# =============================================================================\n",
    "# Few frames, load into memory directly\n",
    "# =============================================================================\n",
    "def generateData(train_dir, dataset_dir, scene, method_name):\n",
    "    assert method_name in ['FgSegNet_M', 'FgSegNet_S'], 'method_name is incorrect'\n",
    "\n",
    "    void_label = -1.\n",
    "\n",
    "    # Given ground-truths, load training frames\n",
    "    # ground-truths end with '*.png'\n",
    "    # training frames end with '*.jpg'\n",
    "\n",
    "    # given ground-truths, load inputs  \n",
    "    Y_list = glob.glob(os.path.join(train_dir, '*.png'))\n",
    "    X_list= glob.glob(os.path.join(dataset_dir, 'input','*.jpg'))\n",
    "\n",
    "    if len(Y_list)<=0 or len(X_list)<=0:\n",
    "        raise ValueError('System cannot find the dataset path or ground-truth path. Please give the correct path.')\n",
    "\n",
    "    X_list_temp = []\n",
    "    for i in range(len(Y_list)):\n",
    "        Y_name = os.path.basename(Y_list[i])\n",
    "        Y_name = Y_name.split('.')[0]\n",
    "        Y_name = Y_name.split('gt')[1]\n",
    "        for j in range(len(X_list)):\n",
    "            X_name = os.path.basename(X_list[j])\n",
    "            X_name = X_name.split('.')[0]\n",
    "            X_name = X_name.split('in')[1]\n",
    "            if (Y_name == X_name):\n",
    "                X_list_temp.append(X_list[j])\n",
    "                break\n",
    "\n",
    "    X_list = X_list_temp\n",
    "\n",
    "    if len(X_list)!=len(Y_list):\n",
    "        raise ValueError('The number of X_list and Y_list must be equal.')\n",
    "\n",
    "    # load training data\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(len(X_list)):\n",
    "        x = kImage.load_img(X_list[i])\n",
    "        x = kImage.img_to_array(x)\n",
    "        X.append(x)\n",
    "\n",
    "        x = kImage.load_img(Y_list[i], grayscale = True)\n",
    "        x = kImage.img_to_array(x)\n",
    "        shape = x.shape\n",
    "        x /= 255.0\n",
    "        x = x.reshape(-1)\n",
    "        idx = np.where(np.logical_and(x>0.25, x<0.8))[0] # find non-ROI\n",
    "        if (len(idx)>0):\n",
    "            x[idx] = void_label\n",
    "        x = x.reshape(shape)\n",
    "        x = np.floor(x)\n",
    "        Y.append(x)\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "\n",
    "    # We do not consider temporal data\n",
    "    idx = list(range(X.shape[0]))\n",
    "    np.random.shuffle(idx)\n",
    "    np.random.shuffle(idx)\n",
    "    X = X[idx]\n",
    "    Y = Y[idx]\n",
    "\n",
    "    if method_name=='FgSegNet_M':\n",
    "        # Image Pyramid\n",
    "        scale2 = []\n",
    "        scale3 = []\n",
    "        for i in range(0, X.shape[0]):\n",
    "           pyramid = tuple(pyramid_gaussian(X[i]/255., max_layer=2, downscale=2))\n",
    "           scale2.append(pyramid[1]*255.) # 2nd scale\n",
    "           scale3.append(pyramid[2]*255.) # 3rd scale\n",
    "           del pyramid\n",
    "\n",
    "        scale2 = np.asarray(scale2)\n",
    "        scale3 = np.asarray(scale3)\n",
    "\n",
    "    # compute class weights\n",
    "    cls_weight_list = []\n",
    "    for i in range(Y.shape[0]):\n",
    "        y = Y[i].reshape(-1)\n",
    "        idx = np.where(y!=void_label)[0]\n",
    "        if(len(idx)>0):\n",
    "            y = y[idx]\n",
    "        lb = np.unique(y) #  0., 1\n",
    "        cls_weight = compute_class_weight('balanced', lb , y)\n",
    "        class_0 = cls_weight[0]\n",
    "        class_1 = cls_weight[1] if len(lb)>1 else 1.0\n",
    "\n",
    "        cls_weight_dict = {0:class_0, 1: class_1}\n",
    "        cls_weight_list.append(cls_weight_dict)\n",
    "\n",
    "    cls_weight_list = np.asarray(cls_weight_list)\n",
    "\n",
    "    if method_name=='FgSegNet_M':\n",
    "        return [X, scale2, scale3, Y, cls_weight_list]\n",
    "    else:\n",
    "        return [X,Y,cls_weight_list]\n",
    "\n",
    "def train(results, scene, mdl_path, vgg_weights_path, method_name):\n",
    "    assert method_name in ['FgSegNet_M', 'FgSegNet_S'], 'method_name is incorrect'\n",
    "\n",
    "    img_shape = results[0][0].shape # (height, width, channel)\n",
    "    model = FgSegNet_M_S_module(lr, reg, img_shape, scene, vgg_weights_path)\n",
    "\n",
    "    if method_name=='FgSegNet_M':\n",
    "        model = model.initModel_M('CDnet')\n",
    "    else:\n",
    "        model = model.initModel_S('CDnet')\n",
    "\n",
    "    # make sure that training input shape equals to model output\n",
    "    input_shape = (img_shape[0], img_shape[1])\n",
    "    output_shape = (model.output._keras_shape[1], model.output._keras_shape[2])\n",
    "    assert input_shape==output_shape, 'Given input shape:' + str(input_shape) + ', but your model outputs shape:' + str(output_shape) \n",
    "\n",
    "    chk = keras.callbacks.ModelCheckpoint(mdl_path, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "    redu = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=reduce_factor, patience=num_patience, verbose=1, mode='auto')\n",
    "    early = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=10, verbose=0, mode='auto')\n",
    "\n",
    "    if method_name=='FgSegNet_M':\n",
    "        model.fit([results[0], results[1], results[2]], results[3], validation_split=val_split, epochs=max_epochs, batch_size=batch_size, \n",
    "                           callbacks=[redu, chk], verbose=1, class_weight=results[4], shuffle = True)\n",
    "    else:\n",
    "        # maybe we can use early stopping instead for FgSegNet_S, and also set max epochs to 100 or 110\n",
    "        model.fit(results[0], results[1], validation_split=val_split, epochs=max_epochs+50, batch_size=batch_size, \n",
    "              callbacks=[redu, early], verbose=1, class_weight=results[2], shuffle = True)\n",
    "        model.save(mdl_path)\n",
    "\n",
    "    del model, results, chk, redu, early\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Main func\n",
    "# =============================================================================\n",
    "#dataset = {\n",
    "#            'baseline':['highway', 'pedestrians', 'office', 'PETS2006'],\n",
    "#            'cameraJitter':['badminton', 'traffic', 'boulevard', 'sidewalk'],\n",
    "#            'badWeather':['skating', 'blizzard', 'snowFall', 'wetSnow'],\n",
    "#            'dynamicBackground':['boats', 'canoe', 'fall', 'fountain01', 'fountain02', 'overpass'],\n",
    "#            'intermittentObjectMotion':['abandonedBox', 'parking', 'sofa', 'streetLight', 'tramstop', 'winterDriveway'],\n",
    "#            'lowFramerate':['port_0_17fps', 'tramCrossroad_1fps', 'tunnelExit_0_35fps', 'turnpike_0_5fps'],\n",
    "#            'nightVideos':['bridgeEntry', 'busyBoulvard', 'fluidHighway', 'streetCornerAtNight', 'tramStation', 'winterStreet'],\n",
    "#            'PTZ':['continuousPan', 'intermittentPan', 'twoPositionPTZCam', 'zoomInZoomOut'],\n",
    "#            'shadow':['backdoor', 'bungalows', 'busStation', 'copyMachine', 'cubicle', 'peopleInShade'],\n",
    "#            'thermal':['corridor', 'diningRoom', 'lakeSide', 'library', 'park'],\n",
    "#            'turbulence':['turbulence0', 'turbulence1', 'turbulence2', 'turbulence3']\n",
    "#}\n",
    "\n",
    "dataset = {\n",
    "            'baseline':['office']\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "\n",
    "method_name = 'FgSegNet_M' # either <FgSegNet_M> or <FgSegNet_S>, default FgSegNet_M\n",
    "\n",
    "num_frames = 50 # either 50 or 200 frames, default 50 frames\n",
    "\n",
    "reduce_factor = 0.1\n",
    "num_patience = 6\n",
    "lr = 1e-4\n",
    "reg=5e-4\n",
    "max_epochs = 60 if num_frames==50 else 50 # 50f->60epochs, 200f->50epochs\n",
    "val_split = 0.2\n",
    "batch_size = 1\n",
    "# =============================================================================\n",
    "\n",
    "# Example: (free to modify)\n",
    "\n",
    "# FgSegNet/FgSegNet/FgSegNet_M_S_CDnet.py\n",
    "# FgSegNet/FgSegNet/FgSegNet_M_S_SBI.py\n",
    "# FgSegNet/FgSegNet/FgSegNet_M_S_UCSD.py\n",
    "# FgSegNet/FgSegNet/FgSegNet_M_S_module.py\n",
    "\n",
    "# FgSegNet/FgSegNet_dataset2014/...\n",
    "# FgSegNet/CDnet2014_dataset/...\n",
    "\n",
    "\n",
    "assert num_frames in [50,200], 'Incorrect number of frames'\n",
    "main_dir = os.path.join('..', method_name)\n",
    "main_mdl_dir = os.path.join(main_dir, 'CDnet', 'models' + str(num_frames))\n",
    "vgg_weights_path = 'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "if not os.path.exists(vgg_weights_path):\n",
    "    # keras func\n",
    "    WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "    vgg_weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                WEIGHTS_PATH_NO_TOP, cache_subdir='models',\n",
    "                                file_hash='6d6bbae143d832006294945121d1f1fc')\n",
    "else:\n",
    "    print('FIle Already Exists')        \n",
    "\n",
    "print('*** Current method >>> ' + method_name + '\\n')\n",
    "for category, scene_list in dataset.items():\n",
    "\n",
    "    mdl_dir = os.path.join(main_mdl_dir, category)\n",
    "    if not os.path.exists(mdl_dir):\n",
    "        os.makedirs(mdl_dir)\n",
    "\n",
    "    for scene in scene_list:\n",
    "        print ('Training ->>> ' + category + ' / ' + scene)\n",
    "\n",
    "        # training frame path and dataset2014 path\n",
    "        train_dir = os.path.join('..', 'FgSegNet_dataset2014', category, scene + str(num_frames))\n",
    "        dataset_dir = os.path.join('..', 'CDnet2014_dataset', category, scene)\n",
    "        results = generateData(train_dir, dataset_dir, scene, method_name)\n",
    "\n",
    "        mdl_path = os.path.join(mdl_dir, 'mdl_' + scene + '.h5')\n",
    "        train(results, scene, mdl_path, vgg_weights_path, method_name)\n",
    "        del results"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
